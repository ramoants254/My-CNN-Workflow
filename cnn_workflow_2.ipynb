{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqy5d5dvCEzy5n7tiiA5T6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramoants254/My-CNN-Workflow/blob/main/cnn_workflow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "* Before we get into the details of convolution, let's discuss the purpose of these layers in the network. We're going to see how these three operations (convolution, ReLU, and maximum pooling) are used to implement the feature extraction process.\n",
        "\n",
        "* The feature extraction performed by the base consists of three basic operations:\n",
        "\n",
        "* Filter an image for a particular feature (convolution)\n",
        "* Detect that feature within the filtered image (ReLU)\n",
        "* Condense the image to enhance the features (maximum pooling)"
      ],
      "metadata": {
        "id": "dNNjHJqo__Rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activations¶\n",
        "* The activations in the network we call feature maps. They are what result when we apply a filter to an image; they contain the visual features the kernel extracts."
      ],
      "metadata": {
        "id": "nS5liXKTCrD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A MaxPool2D layer is much like a Conv2D layer, except that it uses a simple maximum function instead of a kernel, with the pool_size parameter analogous to kernel_size. A MaxPool2D layer doesn't have any trainable weights like a convolutional layer does in its kernel, however."
      ],
      "metadata": {
        "id": "NgXvtysKK6KQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQxFk-45_qOF"
      },
      "outputs": [],
      "source": [
        "# Setup feedback system\n",
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.computer_vision.ex5 import *\n",
        "​\n",
        "# Imports\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "​\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "​\n",
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "​\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
        "​\n",
        "​\n",
        "# Load training and validation sets\n",
        "ds_train_ = image_dataset_from_directory(\n",
        "    '../input/car-or-truck/train',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "ds_valid_ = image_dataset_from_directory(\n",
        "    '../input/car-or-truck/valid',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        ")\n",
        "​\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "​\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = (\n",
        "    ds_train_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "ds_valid = (\n",
        "    ds_valid_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "​"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "​\n",
        "model = keras.Sequential([\n",
        "    # Block One\n",
        "    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n",
        "                  input_shape=[128, 128, 3]),\n",
        "    layers.MaxPool2D(),\n",
        "​\n",
        "    # Block Two\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "​\n",
        "    # Block Three\n",
        "    # YOUR CODE HERE\n",
        "    # ____,\n",
        "​\n",
        "    # Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(6, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "​\n",
        "# Check your answer\n",
        "q_1.check()"
      ],
      "metadata": {
        "id": "z9ffhNrv7teW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2: Batch Normalization"
      ],
      "metadata": {
        "id": "_v2Db9mw_3P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all of the \"factor\" parameters indicate a percent-change\n",
        "augment = keras.Sequential([\n",
        "    # preprocessing.RandomContrast(factor=0.5),\n",
        "    preprocessing.RandomFlip(mode='horizontal'), # meaning, left-to-right\n",
        "    # preprocessing.RandomFlip(mode='vertical'), # meaning, top-to-bottom\n",
        "    # preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n",
        "    # preprocessing.RandomRotation(factor=0.20),\n",
        "    # preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "])\n",
        "\n",
        "\n",
        "ex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(16):\n",
        "    image = augment(ex, training=True)\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(tf.squeeze(image))\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ilf5zw4k_LZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1: Normalization"
      ],
      "metadata": {
        "id": "ert2_JiP_xCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "​\n",
        "model = keras.Sequential([\n",
        "    layers.InputLayer(input_shape=[128, 128, 3]),\n",
        "\n",
        "    # Data Augmentation\n",
        "    # ____,\n",
        "​\n",
        "    # Block One\n",
        "    layers.BatchNormalization(renorm=True),\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "​\n",
        "    # Block Two\n",
        "    layers.BatchNormalization(renorm=True),\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "​\n",
        "    # Block Three\n",
        "    layers.BatchNormalization(renorm=True),\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "​\n",
        "    # Head\n",
        "    layers.BatchNormalization(renorm=True),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "​\n",
        "# Check your answer\n",
        "q_3.check()"
      ],
      "metadata": {
        "id": "PJQCggsS_vB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}