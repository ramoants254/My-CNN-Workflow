{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjSCC/Pa5kCOYt8PvsC/VD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramoants254/My-CNN-Workflow/blob/main/CNN_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "f_HoJxUK5u1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgQBt4Mt5NMZ"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed(31415)\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
        "\n",
        "\n",
        "# Load training and validation sets\n",
        "ds_train_ = image_dataset_from_directory(\n",
        "    '../input/car-or-truck/train',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "ds_valid_ = image_dataset_from_directory(\n",
        "    '../input/car-or-truck/valid',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = (\n",
        "    ds_train_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "ds_valid = (\n",
        "    ds_valid_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Define Pretrained Base\n",
        "* The most commonly used dataset for pretraining is ImageNet, a large dataset of many kind of natural images. Keras includes a variety models pretrained on ImageNet in its applications module. The pretrained model we'll use is called VGG16."
      ],
      "metadata": {
        "id": "vfPjnggH6OuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_base = tf.keras.models.load_model(\n",
        "    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
        ")\n",
        "pretrained_base.trainable = False"
      ],
      "metadata": {
        "id": "NbL5rxfG50PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Attach Head\n",
        "* Next, we attach the classifier head. For this example, we'll use a layer of hidden units (the first Dense layer) followed by a layer to transform the outputs to a probability score for class 1, Truck. The Flatten layer transforms the two dimensional outputs of the base into the one dimensional inputs needed by the head."
      ],
      "metadata": {
        "id": "6TAxiDeK6nme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    pretrained_base,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(6, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "Wp_KBUtz6b9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Train\n",
        "* Finally, let's train the model. Since this is a two-class problem, we'll use the binary versions of crossentropy and accuracy. The adam optimizer generally performs well, so we'll choose it as well."
      ],
      "metadata": {
        "id": "pEqdq5hf7CxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=30,\n",
        "    verbose=0,\n",
        ")"
      ],
      "metadata": {
        "id": "jnHhBOG66bw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When training a neural network, it's always a good idea to examine the loss and metric plots. The history object contains this information in a dictionary history.history. We can use Pandas to convert this dictionary to a dataframe and plot it with a built-in method."
      ],
      "metadata": {
        "id": "SoWq_Szy7bRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
      ],
      "metadata": {
        "id": "SzeytD0h6bIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}